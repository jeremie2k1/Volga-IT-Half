Необходимо полагаться на текстовую информацию, представленную в столбце `Desc`, чтобы классифицировать `Group` и `Cat` для проблемы, запрошенной жителями города.

## Overview Data
Просмотрите предоставленные файлы. Файл `L.csv` для обучения модели и файл `C.csv` для записи результатов. В файле `L.csv` есть две строки, где `Desc` содержит значения `NaN`, которые необходимо удалить. Кроме того, данные из файла `L.csv` не сбалансированы. Проблемы рабочей группы **«Управление домом»** составляют большую часть, немалое количество составляет и категория **«Сантехника»**. Возможно, сейчас необходимо пополнить данные для файла `L.csv`.

## Data Augmentation
Для обогащения данных я использую пакеты инструментов `textattack` и `googletrans`. Основной метод обогащения — `back translate`. Я перевел предоставленный текст с русского на английский, затем применил некоторые методы, такие как `EasyDataAugmenter, WordNetAugmenter, CheckListAugmenter, ...` из пакета `textattack`, затем перевел на несколько других популярных языков и перевел на русский, чтобы обогатить данные для `L.csv`. Поскольку ресурсы компьютера ограничены, я применяю обогащение данных только к выборкам с числом групп и категорий заданий **менее 100**. После этапа обогащения данных мне необходимо их очистить.

## Data Preprocessing
Во-первых, я удалил повторяющиеся строки, используя `drop_duplicates()` в `pandas`. Далее следует серия обычной обработки задач `NLP`, таких как удаление чисел, удаление знаков препинания, удаление `stopwords` и ``. Теперь гарантированы базовые данные для обучения.

## Определение функции потерь
Я определяю функцию потерь в соответствии с формулой многоклассовой потери журнала: `Log_loss=-(1/N)*sum(y_true*log(y_pred))`.

## Постройте модель классификации
Что касается текстовых данных, используемых в моделях, я использую два метода библиотеки `sklearn`: `TfidfVectorizer` и `CountVectorizer`. Построенные модели: `LogisticRegression`, `Naive Bayes`, `SVM`, `Xgboost`, `LSTM`. Наилучшая производительность достигается у `LogisticRegrade` в `CountVectorizer` и `Xgboost`. Я также попробовал `SMOTE` для несбалансированных данных и `Word Vectors`, но результаты были не очень положительными. Я попробовал добавить текст из столбца `Group` после того, как он был отнесен к столбцу `Desc` в качестве входных данных в категорию `Cat`, и получил немного лучшие результаты.

В `src-train/Task 1.ipynb` содержатся проверенные обученные модели.

